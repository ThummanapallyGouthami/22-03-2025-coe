{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nk44YpEC-0pv",
        "outputId": "50216ec3-8518-416c-a72b-c3fb1e254c95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v47JGeho-__W",
        "outputId": "a6d574e1-671a-4d5a-f299-30856162c664"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize"
      ],
      "metadata": {
        "id": "yBAGl_t8_AIE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load spaCy's NLP model\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "LWOCDXB9_ALs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Input text\n",
        "\n",
        "text = \"John works at Google in California. He loves programming and playing football.\"\n",
        "\n",
        "# 1. Segmentation (sentence tokenization)\n",
        "\n",
        "sentences = sent_tokenize(text)\n",
        "\n",
        "print(\"Segmentation:\", sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82R0FnAd_AOm",
        "outputId": "c629ad23-7536-4b4f-de4d-889430ffefa0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segmentation: ['John works at Google in California.', 'He loves programming and playing football.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2. Tokenization (word tokenization)\n",
        "\n",
        "tokens = [word_tokenize(sentence) for sentence in sentences]\n",
        "\n",
        "print(\"Tokenization:\", tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKMBOScV_ARm",
        "outputId": "3782fb83-2ca6-479b-91ee-6dcb4d95d238"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization: [['John', 'works', 'at', 'Google', 'in', 'California', '.'], ['He', 'loves', 'programming', 'and', 'playing', 'football', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 3. Stemming\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "stemmed_tokens = [[stemmer.stem(token) for token in sentence] for sentence in tokens]\n",
        "\n",
        "print(\"Stemming:\", stemmed_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPOIf9xT_AT-",
        "outputId": "58ba839c-74e9-4d83-a919-b5fa23fe5f37"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemming: [['john', 'work', 'at', 'googl', 'in', 'california', '.'], ['he', 'love', 'program', 'and', 'play', 'footbal', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Lemmatization\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "lemmatized_tokens = [[lemmatizer.lemmatize(token) for token in sentence] for sentence in tokens]\n",
        "\n",
        "print(\"Lemmatization:\", lemmatized_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpxmUrW6_AW8",
        "outputId": "d9ed7e2e-c1f2-4887-9466-6930f70e3e73"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatization: [['John', 'work', 'at', 'Google', 'in', 'California', '.'], ['He', 'love', 'programming', 'and', 'playing', 'football', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 5. POS Tagging\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "pos_tags = [(token.text, token.pos_) for token in doc]\n",
        "\n",
        "print(\"POS Tagging:\", pos_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOow1KrJA5Ks",
        "outputId": "3e672c95-1ba9-4113-bed5-38bd30f41556"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POS Tagging: [('John', 'PROPN'), ('works', 'VERB'), ('at', 'ADP'), ('Google', 'PROPN'), ('in', 'ADP'), ('California', 'PROPN'), ('.', 'PUNCT'), ('He', 'PRON'), ('loves', 'VERB'), ('programming', 'VERB'), ('and', 'CCONJ'), ('playing', 'VERB'), ('football', 'NOUN'), ('.', 'PUNCT')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 6. Named Entity Recognition (NER)\n",
        "\n",
        "entities = [(entity.text, entity.label_) for entity in doc.ents]\n",
        "\n",
        "print(\"Named Entities:\", entities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAnlW_xxA5Ps",
        "outputId": "874c4d08-e5ee-4931-afe9-80664b335ead"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Named Entities: [('John', 'PERSON'), ('Google', 'ORG'), ('California', 'GPE')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Parsing (Dependency Parsing)\n",
        "\n",
        "for sent in doc.sents:\n",
        "\n",
        "    for token in sent:\n",
        "\n",
        "        print(f'{token.text:10} -> {token.dep_:10} -> {token.head.text}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCG6YlOfA5T9",
        "outputId": "25d3e898-36d5-42ec-911a-ae4eff5641f5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "John       -> nsubj      -> works\n",
            "works      -> ROOT       -> works\n",
            "at         -> prep       -> works\n",
            "Google     -> pobj       -> at\n",
            "in         -> prep       -> works\n",
            "California -> pobj       -> in\n",
            ".          -> punct      -> works\n",
            "He         -> nsubj      -> loves\n",
            "loves      -> ROOT       -> loves\n",
            "programming -> xcomp      -> loves\n",
            "and        -> cc         -> programming\n",
            "playing    -> conj       -> programming\n",
            "football   -> dobj       -> playing\n",
            ".          -> punct      -> loves\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X68P8dlrA5W1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RUeAGKJjA5fE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}